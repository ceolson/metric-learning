{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eadbe3ce-514c-4b0a-a811-fec6f965d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from scipy import stats, linalg\n",
    "from folktables import ACSDataSource, ACSMobility\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import cupy as cp\n",
    "from cupyx.scipy import stats\n",
    "from cupyx.scipy.sparse.linalg import lobpcg\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fc509cb-cd98-446f-b10e-c41a9e64ffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4553af04-5cd2-4f6d-8fe7-cb96337ff601",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 20\n",
    "r = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "78c982bc-2e04-459b-8b03-8666254ad126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_dist2(x1, x2, K):\n",
    "    return (x2 - x1).T @ K @ (x2 - x1)\n",
    "\n",
    "def generate_synthetic_data(n, r, p, data, S=None):\n",
    "    X = data.sample(n, axis=0)\n",
    "    X = X.loc[:, X.var(axis=0) > 0]\n",
    "    X = X.sample(p, axis=1)\n",
    "    X = cp.array(stats.zscore(cp.array(X), axis=0))\n",
    "   \n",
    "    Astar = cp.random.normal(0, 1, size=(p, r)) / cp.sqrt(p)\n",
    "    Kstar = Astar @ Astar.T\n",
    "\n",
    "    if not S:\n",
    "        Sbar = []\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                for k in range(n):\n",
    "                    if i != j and j != k and k != i:\n",
    "                        Sbar.append((i, j, k))\n",
    "        Sbar = cp.array(Sbar)\n",
    "    \n",
    "        choices = cp.random.choice([False, True], size=len(Sbar), replace=True, p=[0.95, 0.05])\n",
    "        S = Sbar[choices, :]\n",
    "\n",
    "    M = []\n",
    "    for t in S:\n",
    "        i, j, k = t\n",
    "        Mt = cp.outer(X[i], X[k]) + cp.outer(X[k], X[i]) - cp.outer(X[i], X[j]) - cp.outer(X[j], X[i]) + cp.outer(X[j], X[j]) - cp.outer(X[k], X[k])\n",
    "        M.append(Mt)\n",
    "    M = cp.array(M)\n",
    "\n",
    "    probs = 1 / (1 + cp.exp(-cp.einsum('ijj->i', cp.einsum('ijk,kl->ijl', M,  Kstar))))\n",
    "\n",
    "    y = 2 * cp.array(probs > cp.random.random(cp.shape(probs)), dtype=int) - 1\n",
    "    \n",
    "    # y = []\n",
    "    # for t in S:\n",
    "    #     i, j, k = t\n",
    "    #     prob = 1 / (1 + cp.exp(m_dist2(X[i], X[k], Kstar) - m_dist2(X[i], X[j], Kstar)))\n",
    "    #     yt = cp.random.choice([1, -1], size=1, p=[prob, 1 - prob])\n",
    "    #     y.append(yt)\n",
    "    # y = cp.array(y)\n",
    "    \n",
    "    return X, S, y, Astar, Kstar\n",
    "\n",
    "def initialization(n, p, S, X, y):\n",
    "    transition_matrices = [cp.zeros((n - 1, n - 1)) for _ in range(n)]\n",
    "    for t in range(len(S)):\n",
    "        def gap(l, i):\n",
    "            if l < i:\n",
    "                return l\n",
    "            else:\n",
    "                return l - 1\n",
    "        i, j, k = S[t]\n",
    "        i = i.get()\n",
    "        j = j.get()\n",
    "        k = k.get()\n",
    "        transition_matrices[i][gap(j, i), gap(k, i)] = 0.99 if y[t] == 1 else 0.01\n",
    "        transition_matrices[i][gap(k, i), gap(j, i)] = 0.99 if y[t] == -1 else 0.01\n",
    "\n",
    "    for i in range(n):\n",
    "        d = cp.max(cp.sum(transition_matrices[i], axis=1))\n",
    "        transition_matrices[i] = transition_matrices[i] / d\n",
    "\n",
    "        self_loops = cp.diag(1 - cp.sum(transition_matrices[i], axis=1))\n",
    "\n",
    "        transition_matrices[i] += self_loops\n",
    "\n",
    "    dists_from_i = []\n",
    "    for i in range(n):\n",
    "        eigenvalues, eigenvectors = cp.linalg.eigh(transition_matrices[i])\n",
    "        leading_index = cp.where(cp.isclose(eigenvalues, 1))[0]\n",
    "        leading_eigenvector = cp.abs(eigenvectors[:, leading_index].real)\n",
    "        dists_wo_i = cp.log(leading_eigenvector)\n",
    "        if not cp.all(cp.isfinite(dists_wo_i)):\n",
    "            print(i)\n",
    "        dists = cp.zeros(n)\n",
    "        cp.put(dists, list(range(i)) + list(range(i+1, n)), dists_wo_i)\n",
    "        dists_from_i.append(dists)\n",
    "    D = cp.stack(dists_from_i)\n",
    "\n",
    "    J = cp.identity(n) - (cp.ones((n, 1)) @ cp.ones((1, n))) / n\n",
    "    H = - J @ D @ J / 2\n",
    "    Xprime = J @ X\n",
    "    \n",
    "    XtHX = Xprime.T @ H @ Xprime / (n**2)\n",
    "    Sigma = Xprime.T @ Xprime / n\n",
    "    eigenvalues, eigenvectors = lobpcg(A=XtHX, B=Sigma, X=cp.random.normal(size=(p,r)))\n",
    "    U = eigenvectors[:, cp.argsort(eigenvalues)[-r:]]\n",
    "    Lambda = cp.sort(eigenvalues)[-r:]\n",
    "    AAt = U @ cp.diag(Lambda) @ U.T\n",
    "    \n",
    "    V, s, W = cp.linalg.svd(AAt)\n",
    "    \n",
    "    top_r_indicies = cp.argsort(s)[:r]\n",
    "    V_r = V[:, top_r_indicies].reshape((p, r))\n",
    "    s_r = s[top_r_indicies]\n",
    "    Ahat = V_r @ cp.sqrt(cp.diag(s_r))\n",
    "\n",
    "    return Ahat\n",
    "\n",
    "def L(A, triplets): \n",
    "    yMtAs = torch.einsum('bij,jk->bik', triplets, A)\n",
    "    yMtAATs = torch.einsum('bij,jk->bik', yMtAs, torch.transpose(A, 0, 1))\n",
    "    TryMtAATs = torch.einsum('bii->b', yMtAATs)\n",
    "    losses = torch.log(1 + torch.exp(-TryMtAATs))\n",
    "    \n",
    "    return torch.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0962204a-4fba-4722-8842-f1dc719d6c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 610.06 MiB, increment: 126.94 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit synthetic_data = pd.DataFrame(cp.random.normal(size=(1000, 50)).get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c3a83f-2b0e-4619-82a6-4e5e2e47f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 3\n",
    "p = 20\n",
    "%memit X, S, y, Astar, Kstar = generate_synthetic_data(100, r, p, synthetic_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648b9102-87e6-411b-be62-fbd12b11f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]: # [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]:\n",
    "    \n",
    "\n",
    "    \n",
    "    print(\"Generating synthetic data...\")   \n",
    "    X, S, y, Astar, Kstar = generate_synthetic_data(n, r, p, synthetic_data)\n",
    "    print(cp.shape(X))\n",
    "    \n",
    "    cp.save(\"Astar.cpy\", Astar.get())\n",
    "    \n",
    "    print(\"Initializing...\")\n",
    "    A0 = initialization(n, p, S, y)\n",
    "    \n",
    "    print(n)\n",
    "    print(cp.linalg.norm(Astar - A0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4aa991b9-e1a1-4fd1-a5ca-a8f49abe7e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48251"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a39bb7-20a7-4541-b36e-da4f11db5b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metriclearning2",
   "language": "python",
   "name": "metriclearning2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
