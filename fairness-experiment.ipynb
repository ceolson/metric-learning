{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home10/colson/.local/lib/python3.10/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from folktables import ACSDataSource, ACSMobility\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from scipy import stats\n",
    "from scipy.sparse.linalg import lobpcg\n",
    "from scipy.linalg import eigh, eig\n",
    "import pandas as pd\n",
    "from inFairness.distances import MahalanobisDistances, SquaredEuclideanDistance, LogisticRegSensitiveSubspace\n",
    "from inFairness.fairalgo import SenSeI\n",
    "from inFairness.auditor import SenSeIAuditor, SenSRAuditor\n",
    "from tqdm.auto import tqdm\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return data, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return z * (z > 0)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "def softmax(z):\n",
    "    exponentials = np.exp(z - np.max(z))\n",
    "    return exponentials / exponentials.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 3\n",
    "p = 30\n",
    "n = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"TX\"], download=True)\n",
    "acs_data_adult = acs_data[acs_data[\"AGEP\"] >= 18]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(206826, 219)\n"
     ]
    }
   ],
   "source": [
    "acs_data_cleaned = acs_data_adult.select_dtypes(include=[\"float64\", \"int64\"])\n",
    "acs_data_cleaned = acs_data_cleaned.loc[:, ~(acs_data_cleaned.isna().any())]\n",
    "acs_data_cleaned = acs_data_cleaned.loc[:, (acs_data_cleaned.var(axis=0) > 0)]\n",
    "acs_data_cleaned = acs_data_cleaned.sample(frac=1, axis=0)\n",
    "print(np.shape(np.array(acs_data_cleaned)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data = pd.DataFrame(np.random.normal(0, 1, size=(2 * n, p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating synthetic data...\")\n",
    "X = clean_data(2 * n, p, synthetic_data)\n",
    "X_train = X[:n]\n",
    "X_test = X[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 30) (75, 30)\n"
     ]
    }
   ],
   "source": [
    "M, S, y, Astar, Kstar = generate_synthetic_data(n, r, p, X_train)\n",
    "\n",
    "print(np.shape(X_train), np.shape(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A0 = initialization(n, r, p, S, X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5241586420597083"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(A0 @ A0.T - Kstar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 tensor(0.5076, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.18603579772551634\n",
      "20 tensor(0.5040, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.1021843662016137\n",
      "30 tensor(0.5033, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.06592304936157556\n",
      "40 tensor(0.5031, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.04770017738727625\n",
      "50 tensor(0.5031, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.03818291918469853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A_iterates = []\n",
    "A = torch.tensor(A0, requires_grad=True, device=\"cpu\")\n",
    "dists = []\n",
    "\n",
    "y_tensor = torch.tensor(y, device=\"cpu\")\n",
    "M_tensor = torch.tensor(M, device=\"cpu\")\n",
    "for iterate in range(100):\n",
    "    loss = L(A, y_tensor, M_tensor)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        A -= A.grad * 0.5\n",
    "        A_iterates.append(A.detach().cpu().numpy())\n",
    "        dists.append(np.linalg.norm(A.detach().cpu().numpy() @ A.detach().cpu().numpy().T - Kstar))\n",
    "        A.grad.zero_()\n",
    "    if iterate % 10 == 9:\n",
    "        print(iterate + 1, loss, np.linalg.norm(A.detach().cpu().numpy() @ A.detach().cpu().numpy().T - Kstar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ahat = A_iterates[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03483869761803121"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(Ahat @ Ahat.T - Kstar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lin1star = np.random.normal(0, 1, size=(p, 20))\n",
    "# lin2star = np.random.normal(0, 1, size=(20, 20))\n",
    "# lin3star = np.random.normal(0, 1, size=20)\n",
    "# epsilon = np.random.normal(0, 0.01, size=2 * n)\n",
    "\n",
    "# Y_probs = relu(np.einsum(\"ij,jk->ik\", X, lin1star))\n",
    "# Y_probs = relu(np.einsum(\"ij,jk->ik\", Y_probs, lin2star))\n",
    "# Y_probs = sigmoid(np.einsum(\"ij,j->i\", Y_probs, lin3star))\n",
    "\n",
    "Y_probs = np.sign(X[:, 0]) / 10 + 0.5\n",
    "\n",
    "Y = (np.random.random(size=2 * n) < Y_probs).astype(int)\n",
    "\n",
    "Y_train = Y[:n]\n",
    "Y_test = Y[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = torch.Tensor(X_train)\n",
    "Y_train_t = torch.Tensor(Y_train)\n",
    "\n",
    "X_test_t = torch.Tensor(X_test)\n",
    "Y_test_t = torch.Tensor(Y_test)\n",
    "\n",
    "train_dataset = TrainDataset(X_train_t, Y_train_t)\n",
    "test_dataset = TrainDataset(X_test_t, Y_test_t)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=8)\n",
    "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.lin1 = torch.nn.Linear(p, 20, bias=False)\n",
    "        self.lin2 = torch.nn.Linear(20, 20, bias=False)\n",
    "        self.lin3 = torch.nn.Linear(20, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.lin1(x))\n",
    "        x = torch.nn.functional.relu(self.lin2(x))\n",
    "        return torch.nn.functional.sigmoid(self.lin3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network_standard = NeuralNet()\n",
    "optimizer = torch.optim.Adam(network_standard.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.functional.binary_cross_entropy\n",
    "\n",
    "network_standard.train()\n",
    "\n",
    "for epoch in range(1000):\n",
    "\n",
    "    for x, y in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = network_standard(x).squeeze()\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.9736e-07, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_metric = MahalanobisDistances()\n",
    "input_metric.fit(torch.Tensor(Ahat @ Ahat.T))\n",
    "\n",
    "input_metric_true = MahalanobisDistances()\n",
    "input_metric_true.fit(torch.Tensor(Astar @ Astar.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_metric = SquaredEuclideanDistance()\n",
    "output_metric.fit(num_dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 5.0\n",
    "eps = 0.1\n",
    "auditor_nsteps = 100\n",
    "auditor_lr = 0.001\n",
    "\n",
    "alg = SenSeI(network, input_metric, output_metric, loss_fn, rho, eps, auditor_nsteps, auditor_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "alg.train()\n",
    "\n",
    "for epoch in range(100):\n",
    "    for x, y in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        result = alg(x, torch.reshape(y, (-1, 1)))\n",
    "        result.loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0019, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# auditor = SenSRAuditor(torch.nn.L1Loss, output_metric, nsteps, lr)\n",
    "\n",
    "auditor = SenSeIAuditor(input_metric, output_metric, auditor_nsteps, auditor_lr)\n",
    "auditor_true = SenSeIAuditor(input_metric_true, output_metric, auditor_nsteps, auditor_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AuditorResponse(lossratio_mean=1.0001038, lossratio_std=0.18289803, lower_bound=0.9960926247913363, threshold=None, pval=None, confidence=None, is_model_fair=None)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auditor.audit(network, X_test_t, Y_test_t, torch.nn.functional.l1_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AuditorResponse(lossratio_mean=1.0173771, lossratio_std=0.22246106, lower_bound=1.012498259726007, threshold=None, pval=None, confidence=None, is_model_fair=None)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auditor_true.audit(network, X_test_t, Y_test_t, torch.nn.functional.l1_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = auditor.generate_worst_case_examples(network, X_test_t, torch.Tensor([0.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103.48351"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratios = []\n",
    "for X_1 in X_test_t:\n",
    "    for X_2 in X_test_t:\n",
    "        ratios.append((output_metric(network(X_1), network(X_2)) / input_metric(X_1, X_2)).detach().numpy())\n",
    "ratios = np.array(ratios)\n",
    "np.max(ratios[~np.isnan(ratios)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.06766"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratios = []\n",
    "for X_1 in X_test_t:\n",
    "    for X_2 in X_test_t:\n",
    "        ratios.append((output_metric(network(X_1), network(X_2)) / input_metric_true(X_1, X_2)).detach().numpy())\n",
    "ratios = np.array(ratios)\n",
    "np.max(ratios[~np.isnan(ratios)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metriclearning2",
   "language": "python",
   "name": "metriclearning2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
