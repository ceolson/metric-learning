{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ceolson/miniforge3/lib/python3.12/site-packages/inFairness/utils/ndcg.py:37: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  vect_normalized_discounted_cumulative_gain = vmap(\n",
      "/Users/ceolson/miniforge3/lib/python3.12/site-packages/inFairness/utils/ndcg.py:48: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  monte_carlo_vect_ndcg = vmap(vect_normalized_discounted_cumulative_gain, in_dims=(0,))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from folktables import ACSDataSource, ACSMobility, ACSIncome\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from scipy import stats\n",
    "from scipy.sparse.linalg import lobpcg\n",
    "from scipy.linalg import eigh, eig\n",
    "import pandas as pd\n",
    "from inFairness.distances import MahalanobisDistances, SquaredEuclideanDistance, LogisticRegSensitiveSubspace\n",
    "from inFairness.fairalgo import SenSeI\n",
    "from inFairness.auditor import SenSeIAuditor, SenSRAuditor\n",
    "from tqdm.auto import tqdm\n",
    "from utils import *\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.lin1 = torch.nn.Linear(p, 20, bias=False)\n",
    "        self.lin2 = torch.nn.Linear(20, 20, bias=False)\n",
    "        self.lin3 = torch.nn.Linear(20, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.lin1(x))\n",
    "        x = torch.nn.functional.relu(self.lin2(x))\n",
    "        return torch.nn.functional.sigmoid(self.lin3(x))\n",
    "\n",
    "def relu(z):\n",
    "    return z * (z > 0)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "def softmax(z):\n",
    "    exponentials = np.exp(z - np.max(z))\n",
    "    return exponentials / np.sum(exponentials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 3\n",
    "p = 30\n",
    "n = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"TX\"], download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acs_data_cleaned = acs_data_adult.select_dtypes(include=[\"float64\", \"int64\"])\n",
    "# acs_data_cleaned = acs_data_cleaned.loc[:, ~(acs_data_cleaned.isna().any())]\n",
    "# acs_data_cleaned = acs_data_cleaned.loc[:, (acs_data_cleaned.var(axis=0) > 0)]\n",
    "# acs_data_cleaned = acs_data_cleaned.sample(frac=1, axis=0)\n",
    "# print(np.shape(np.array(acs_data_cleaned)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels, _ = ACSMobility.df_to_pandas(acs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = pd.DataFrame(np.random.normal(0, 1, size=(2 * n, p)))\n",
    "# labels = pd.DataFrame(np.random.uniform(0, 1, size=2 * n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_data(2 * n, len(features.columns), features, cut_columns=False)\n",
    "X_train = X[:n]\n",
    "X_test = X[n:]\n",
    "\n",
    "Y = labels.head(2 * n)\n",
    "Y_train = Y[:n]\n",
    "Y_test = Y[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.shape(X)[-1]\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "Astar = np.random.normal(0, 1, size=(p, r)) / (np.sqrt(p) * np.sqrt(r))\n",
    "Kstar = Astar @ Astar.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A0 = np.random.normal(0, 1, size=(p, r)) / (np.sqrt(p) * np.sqrt(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7749293773359504)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(A0 @ A0.T - Kstar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 tensor(0.5083, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.06637228153986997\n",
      "2000 tensor(0.5105, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.04374176555941999\n",
      "3000 tensor(0.5304, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.04547819723562127\n",
      "4000 tensor(0.5163, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.04507119825817106\n",
      "5000 tensor(0.5115, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.03689029296333616\n",
      "6000 tensor(0.5102, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.03320806553516685\n",
      "7000 tensor(0.5059, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.03915279235921491\n",
      "8000 tensor(0.5257, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.05017862944586293\n",
      "9000 tensor(0.5211, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.04617225083549247\n",
      "10000 tensor(0.4902, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.04848673685787847\n",
      "11000 tensor(0.5116, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.03951240881280579\n",
      "12000 tensor(0.5284, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.04251651740568991\n",
      "13000 tensor(0.5150, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.05468408081089873\n",
      "14000 tensor(0.5059, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.046183989967196304\n",
      "15000 tensor(0.5068, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.0434264816573918\n",
      "16000 tensor(0.5212, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.04577561905733108\n",
      "17000 tensor(0.4746, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.04810573809784823\n",
      "18000 tensor(0.4940, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.0377278811094814\n",
      "19000 tensor(0.4974, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.04508347887280259\n",
      "20000 tensor(0.5132, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.04117057748059442\n"
     ]
    }
   ],
   "source": [
    "A_iterates = []\n",
    "A = torch.tensor(A0, requires_grad=True, device=\"cpu\").to(torch.float64)\n",
    "dists = []\n",
    "\n",
    "for iterate in range(20000):\n",
    "    S = np.random.choice(range(X_train.shape[0]), replace=True, size=(1000, 3))\n",
    "    M = []\n",
    "    for t in S:\n",
    "        i, j, k = t\n",
    "        Mt = np.outer(X_train[i], X[k]) + np.outer(X_train[k], X[i]) \\\n",
    "            - np.outer(X_train[i], X[j]) - np.outer(X_train[j], X[i]) \\\n",
    "            + np.outer(X_train[j], X[j]) - np.outer(X_train[k], X[k])\n",
    "        M.append(Mt)\n",
    "    M = np.array(M)\n",
    "    \n",
    "    probs = 1 / (1 + np.exp(-np.einsum('ijj->i', np.einsum('ijk,kl->ijl', M, Kstar))))\n",
    "\n",
    "    y = 2 * np.array(probs > np.random.random(np.shape(probs)), dtype=int) - 1\n",
    "    \n",
    "    loss = L(A, torch.Tensor(y), torch.Tensor(M).to(torch.float64))\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        A -= A.grad * 0.1\n",
    "        A_iterates.append(A.detach().cpu().numpy())\n",
    "        dists.append(np.linalg.norm(A.detach().cpu().numpy() @ A.detach().cpu().numpy().T - Kstar))\n",
    "        A.grad.zero_()\n",
    "    if iterate % 1000 == -1 % 1000:\n",
    "        print(iterate + 1, loss, np.linalg.norm(A.detach().cpu().numpy() @ A.detach().cpu().numpy().T - Kstar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ahat = A_iterates[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.04117057748059442)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(Ahat @ Ahat.T - Kstar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = torch.Tensor(np.array(X_train))\n",
    "Y_train_t = torch.Tensor(np.array(Y_train))\n",
    "\n",
    "X_test_t = torch.Tensor(np.array(X_test))\n",
    "Y_test_t = torch.Tensor(np.array(Y_test))\n",
    "\n",
    "train_dataset = TrainDataset(X_train_t, Y_train_t)\n",
    "test_dataset = TrainDataset(X_test_t, Y_test_t)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=8)\n",
    "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.lin1 = torch.nn.Linear(p, 20, bias=False)\n",
    "        self.lin2 = torch.nn.Linear(20, 20, bias=False)\n",
    "        self.lin3 = torch.nn.Linear(20, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.lin1(x))\n",
    "        x = torch.nn.functional.relu(self.lin2(x))\n",
    "        return torch.nn.functional.sigmoid(self.lin3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network_standard = NeuralNet()\n",
    "optimizer = torch.optim.Adam(network_standard.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.functional.binary_cross_entropy\n",
    "\n",
    "network_standard.train()\n",
    "\n",
    "for epoch in range(200):\n",
    "\n",
    "    for x, y in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = network_standard(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_loss = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0468, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_metric = MahalanobisDistances()\n",
    "input_metric.fit(torch.Tensor(Ahat @ Ahat.T))\n",
    "\n",
    "input_metric_true = MahalanobisDistances()\n",
    "input_metric_true.fit(torch.Tensor(Astar @ Astar.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_metric = SquaredEuclideanDistance()\n",
    "output_metric.fit(num_dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 5.0\n",
    "eps = 0.1\n",
    "auditor_nsteps = 100\n",
    "auditor_lr = 0.001\n",
    "\n",
    "alg = SenSeI(network, input_metric, output_metric, loss_fn, rho, eps, auditor_nsteps, auditor_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "alg.train()\n",
    "\n",
    "for epoch in range(4000):\n",
    "    for x, y in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        result = alg(x, torch.reshape(y, (-1, 1)))\n",
    "        result.loss.backward()\n",
    "        optimizer.step()\n",
    "    if result.loss < standard_loss:\n",
    "        print(\"Stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2626, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# auditor = SenSRAuditor(torch.nn.L1Loss, output_metric, nsteps, lr)\n",
    "\n",
    "auditor = SenSeIAuditor(input_metric, output_metric, auditor_nsteps, auditor_lr)\n",
    "auditor_true = SenSeIAuditor(input_metric_true, output_metric, auditor_nsteps, auditor_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ceolson/miniforge3/lib/python3.12/site-packages/inFairness/auditor/auditor.py:54: RuntimeWarning: divide by zero encountered in divide\n",
      "  loss_ratio = np.divide(loss_vals_adversarial, loss_vals_original)\n",
      "/Users/ceolson/miniforge3/lib/python3.12/site-packages/inFairness/auditor/auditor.py:54: RuntimeWarning: invalid value encountered in divide\n",
      "  loss_ratio = np.divide(loss_vals_adversarial, loss_vals_original)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AuditorResponse(lossratio_mean=np.float32(1.2119776), lossratio_std=np.float32(1.60599), lower_bound=np.float64(1.022320441179178), threshold=None, pval=None, confidence=None, is_model_fair=None)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auditor.audit(network, X_test_t, Y_test_t, torch.nn.functional.l1_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AuditorResponse(lossratio_mean=np.float32(1.276018), lossratio_std=np.float32(1.2474141), lower_bound=np.float64(1.128706390174043), threshold=None, pval=None, confidence=None, is_model_fair=None)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auditor_true.audit(network, X_test_t, Y_test_t, torch.nn.functional.l1_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(174.7098)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratios = []\n",
    "for X_1 in X_test_t:\n",
    "    for X_2 in X_test_t:\n",
    "        ratios.append((output_metric(network(X_1), network(X_2)) / input_metric(X_1, X_2)).detach().numpy())\n",
    "ratios = np.array(ratios)\n",
    "np.max(ratios[~np.isnan(ratios)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(292.29953)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratios = []\n",
    "for X_1 in X_test_t:\n",
    "    for X_2 in X_test_t:\n",
    "        ratios.append((output_metric(network(X_1), network(X_2)) / input_metric_true(X_1, X_2)).detach().numpy())\n",
    "ratios = np.array(ratios)\n",
    "np.max(ratios[~np.isnan(ratios)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AuditorResponse(lossratio_mean=np.float32(1.1828899), lossratio_std=np.float32(1.0637991), lower_bound=np.float64(1.0572620592616555), threshold=None, pval=None, confidence=None, is_model_fair=None)\n"
     ]
    }
   ],
   "source": [
    "print(auditor_true.audit(network, X_test_t, Y_test_t, torch.nn.functional.l1_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
